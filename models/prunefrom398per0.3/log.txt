root-- VOC2007
Pruning round 1, load model from models/pruneFromws1/Epoch-1260-Loss-3.488939012799944.pth
SSD(
  (base_net): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(4, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(6, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)
      (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(6, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=11, bias=False)
      (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(11, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=11, bias=False)
      (1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(11, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=21, bias=False)
      (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(21, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(21, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=21, bias=False)
      (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(21, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=41, bias=False)
      (1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(41, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=41, bias=False)
      (1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(41, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=41, bias=False)
      (1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(41, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=41, bias=False)
      (1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(41, 41, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(41, 41, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=41, bias=False)
      (1): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(41, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(4, 81, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(81, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=81, bias=False)
      (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(81, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (extras): ModuleList(
    (0): Sequential(
      (0): Conv2d(24, 21, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(21, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=21)
        (1): ReLU()
        (2): Conv2d(21, 12, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): Sequential(
      (0): Conv2d(12, 11, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=11)
        (1): ReLU()
        (2): Conv2d(11, 7, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): Sequential(
      (0): Conv2d(7, 11, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=11)
        (1): ReLU()
        (2): Conv2d(11, 7, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): Sequential(
      (0): Conv2d(7, 11, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(11, 11, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=11)
        (1): ReLU()
        (2): Conv2d(11, 73, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (classification_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (1): ReLU()
      (2): Conv2d(4, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
      (1): ReLU()
      (2): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12)
      (1): ReLU()
      (2): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(73, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (regression_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)
      (1): ReLU()
      (2): Conv2d(4, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24)
      (1): ReLU()
      (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12)
      (1): ReLU()
      (2): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(73, 24, kernel_size=(1, 1), stride=(1, 1))
  )
  (source_layer_add_ons): ModuleList()
)
Saved prune model models/prunefrom398per0.3/prune.pth
Number of Parameters: 0.0M
Epoch: 0, Validation Loss: 5.2281, Validation Regression Loss 2.8792, Validation Classification Loss: 2.3489
Saved model models/prunefrom398per0.3/Epoch-0-Loss-5.228137765611921.pth
Epoch: 10, Validation Loss: 4.7017, Validation Regression Loss 2.4396, Validation Classification Loss: 2.2621
Saved model models/prunefrom398per0.3/Epoch-10-Loss-4.701711518423898.pth
Epoch: 20, Validation Loss: 4.4941, Validation Regression Loss 2.2424, Validation Classification Loss: 2.2517
Saved model models/prunefrom398per0.3/Epoch-20-Loss-4.494087014879499.pth
Epoch: 30, Validation Loss: 4.4346, Validation Regression Loss 2.1912, Validation Classification Loss: 2.2434
Saved model models/prunefrom398per0.3/Epoch-30-Loss-4.434590067182269.pth
Epoch: 40, Validation Loss: 4.3499, Validation Regression Loss 2.1083, Validation Classification Loss: 2.2416
Saved model models/prunefrom398per0.3/Epoch-40-Loss-4.34994159426008.pth
Epoch: 50, Validation Loss: 4.2903, Validation Regression Loss 2.0538, Validation Classification Loss: 2.2365
Saved model models/prunefrom398per0.3/Epoch-50-Loss-4.290311132158552.pth
Epoch: 60, Validation Loss: 4.2738, Validation Regression Loss 2.0394, Validation Classification Loss: 2.2344
Saved model models/prunefrom398per0.3/Epoch-60-Loss-4.273815427507673.pth
Epoch: 70, Validation Loss: 4.2203, Validation Regression Loss 1.9861, Validation Classification Loss: 2.2342
Saved model models/prunefrom398per0.3/Epoch-70-Loss-4.220306805201939.pth
Epoch: 80, Validation Loss: 4.1664, Validation Regression Loss 1.9428, Validation Classification Loss: 2.2236
Saved model models/prunefrom398per0.3/Epoch-80-Loss-4.166415623256138.pth
Epoch: 90, Validation Loss: 4.1358, Validation Regression Loss 1.9147, Validation Classification Loss: 2.2211
Saved model models/prunefrom398per0.3/Epoch-90-Loss-4.1358016559055875.pth
Epoch: 100, Validation Loss: 4.1448, Validation Regression Loss 1.9199, Validation Classification Loss: 2.2249
Saved model models/prunefrom398per0.3/Epoch-100-Loss-4.144782134464809.pth
Epoch: 110, Validation Loss: 4.1026, Validation Regression Loss 1.8848, Validation Classification Loss: 2.2178
Saved model models/prunefrom398per0.3/Epoch-110-Loss-4.102634055273874.pth
Epoch: 120, Validation Loss: 4.1155, Validation Regression Loss 1.8942, Validation Classification Loss: 2.2213
Saved model models/prunefrom398per0.3/Epoch-120-Loss-4.115463529314313.pth
Epoch: 130, Validation Loss: 4.1159, Validation Regression Loss 1.8972, Validation Classification Loss: 2.2187
Saved model models/prunefrom398per0.3/Epoch-130-Loss-4.11587609563555.pth
Epoch: 140, Validation Loss: 4.0837, Validation Regression Loss 1.8716, Validation Classification Loss: 2.2121
Saved model models/prunefrom398per0.3/Epoch-140-Loss-4.083662373679025.pth
Epoch: 150, Validation Loss: 4.0763, Validation Regression Loss 1.8642, Validation Classification Loss: 2.2120
Saved model models/prunefrom398per0.3/Epoch-150-Loss-4.076259136199951.pth
Epoch: 160, Validation Loss: 4.0696, Validation Regression Loss 1.8573, Validation Classification Loss: 2.2123
Saved model models/prunefrom398per0.3/Epoch-160-Loss-4.069611515317645.pth
Epoch: 170, Validation Loss: 4.0537, Validation Regression Loss 1.8419, Validation Classification Loss: 2.2118
Saved model models/prunefrom398per0.3/Epoch-170-Loss-4.053741421018328.pth
Epoch: 180, Validation Loss: 4.0620, Validation Regression Loss 1.8508, Validation Classification Loss: 2.2112
Saved model models/prunefrom398per0.3/Epoch-180-Loss-4.061970097678048.pth
Epoch: 190, Validation Loss: 4.0559, Validation Regression Loss 1.8448, Validation Classification Loss: 2.2111
Saved model models/prunefrom398per0.3/Epoch-190-Loss-4.055851834160941.pth
Epoch: 199, Validation Loss: 4.0570, Validation Regression Loss 1.8467, Validation Classification Loss: 2.2103
Saved model models/prunefrom398per0.3/Epoch-199-Loss-4.056980950491769.pth
