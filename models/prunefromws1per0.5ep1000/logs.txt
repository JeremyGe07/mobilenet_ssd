root-- VOC2007
Pruning round 1, load model from models/ep1000ws1pr/mb1-ssd-lite-Epoch-945-Loss-3.2492578540529524.pth
SSD(
  (base_net): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (extras): ModuleList(
    (0): Sequential(
      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)
        (1): ReLU()
        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): Sequential(
      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
        (1): ReLU()
        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): Sequential(
      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
        (1): ReLU()
        (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)
        (1): ReLU()
        (2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (classification_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
      (1): ReLU()
      (2): Conv2d(128, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      (1): ReLU()
      (2): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(128, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (regression_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
      (1): ReLU()
      (2): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      (1): ReLU()
      (2): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))
  )
  (source_layer_add_ons): ModuleList()
)
Saved prune model models/prunefromws1per0.5ep1000/prune.pth
Number of Parameters: 0.2M
Epoch: 0, Validation Loss: 5.3079, Validation Regression Loss 2.9467, Validation Classification Loss: 2.3613
Saved model models/prunefromws1per0.5ep1000/Epoch-0-Loss-5.307927472250802.pth
Epoch: 10, Validation Loss: 4.6840, Validation Regression Loss 2.4145, Validation Classification Loss: 2.2695
Saved model models/prunefromws1per0.5ep1000/Epoch-10-Loss-4.684002603803362.pth
Epoch: 20, Validation Loss: 4.3202, Validation Regression Loss 2.1517, Validation Classification Loss: 2.1685
Saved model models/prunefromws1per0.5ep1000/Epoch-20-Loss-4.320227486746652.pth
Epoch: 30, Validation Loss: 4.1554, Validation Regression Loss 1.9693, Validation Classification Loss: 2.1862
Saved model models/prunefromws1per0.5ep1000/Epoch-30-Loss-4.155446222850254.pth
Epoch: 40, Validation Loss: 3.9111, Validation Regression Loss 1.7679, Validation Classification Loss: 2.1432
Saved model models/prunefromws1per0.5ep1000/Epoch-40-Loss-3.9111156123025075.pth
Epoch: 50, Validation Loss: 3.7151, Validation Regression Loss 1.6023, Validation Classification Loss: 2.1128
Saved model models/prunefromws1per0.5ep1000/Epoch-50-Loss-3.7150844505855014.pth
Epoch: 60, Validation Loss: 3.6495, Validation Regression Loss 1.5514, Validation Classification Loss: 2.0981
Saved model models/prunefromws1per0.5ep1000/Epoch-60-Loss-3.649489232472011.pth
Epoch: 70, Validation Loss: 3.6146, Validation Regression Loss 1.5186, Validation Classification Loss: 2.0960
Saved model models/prunefromws1per0.5ep1000/Epoch-70-Loss-3.6146162918635776.pth
Epoch: 80, Validation Loss: 3.5792, Validation Regression Loss 1.4727, Validation Classification Loss: 2.1065
Saved model models/prunefromws1per0.5ep1000/Epoch-80-Loss-3.5791665826525008.pth
Epoch: 90, Validation Loss: 3.6207, Validation Regression Loss 1.5002, Validation Classification Loss: 2.1205
Saved model models/prunefromws1per0.5ep1000/Epoch-90-Loss-3.620722089494978.pth
Epoch: 100, Validation Loss: 3.5795, Validation Regression Loss 1.4858, Validation Classification Loss: 2.0937
Saved model models/prunefromws1per0.5ep1000/Epoch-100-Loss-3.579456465584891.pth
Epoch: 110, Validation Loss: 3.5272, Validation Regression Loss 1.4204, Validation Classification Loss: 2.1067
Saved model models/prunefromws1per0.5ep1000/Epoch-110-Loss-3.5271839754922047.pth
Epoch: 120, Validation Loss: 3.5196, Validation Regression Loss 1.4283, Validation Classification Loss: 2.0913
Saved model models/prunefromws1per0.5ep1000/Epoch-120-Loss-3.5195844173431396.pth
Epoch: 130, Validation Loss: 3.6516, Validation Regression Loss 1.5571, Validation Classification Loss: 2.0945
Saved model models/prunefromws1per0.5ep1000/Epoch-130-Loss-3.6516121455601285.pth
Epoch: 140, Validation Loss: 3.5645, Validation Regression Loss 1.4788, Validation Classification Loss: 2.0857
Saved model models/prunefromws1per0.5ep1000/Epoch-140-Loss-3.5645293848855153.pth
Epoch: 150, Validation Loss: 3.5331, Validation Regression Loss 1.4323, Validation Classification Loss: 2.1008
Saved model models/prunefromws1per0.5ep1000/Epoch-150-Loss-3.533097675868443.pth
Epoch: 160, Validation Loss: 3.5722, Validation Regression Loss 1.4793, Validation Classification Loss: 2.0929
Saved model models/prunefromws1per0.5ep1000/Epoch-160-Loss-3.5722193717956543.pth
Epoch: 170, Validation Loss: 3.6117, Validation Regression Loss 1.5056, Validation Classification Loss: 2.1061
Saved model models/prunefromws1per0.5ep1000/Epoch-170-Loss-3.6117453234536305.pth
Epoch: 180, Validation Loss: 3.5704, Validation Regression Loss 1.5135, Validation Classification Loss: 2.0570
Saved model models/prunefromws1per0.5ep1000/Epoch-180-Loss-3.5704353536878313.pth
Epoch: 190, Validation Loss: 3.4929, Validation Regression Loss 1.4274, Validation Classification Loss: 2.0656
Saved model models/prunefromws1per0.5ep1000/Epoch-190-Loss-3.4929250308445523.pth
Epoch: 200, Validation Loss: 3.5672, Validation Regression Loss 1.4515, Validation Classification Loss: 2.1156
Saved model models/prunefromws1per0.5ep1000/Epoch-200-Loss-3.5671750136784146.pth
Epoch: 210, Validation Loss: 3.6248, Validation Regression Loss 1.5285, Validation Classification Loss: 2.0963
Saved model models/prunefromws1per0.5ep1000/Epoch-210-Loss-3.6248301437922885.pth
Epoch: 220, Validation Loss: 3.4871, Validation Regression Loss 1.4278, Validation Classification Loss: 2.0593
Saved model models/prunefromws1per0.5ep1000/Epoch-220-Loss-3.487064940588815.pth
Epoch: 230, Validation Loss: 3.5220, Validation Regression Loss 1.4366, Validation Classification Loss: 2.0854
Saved model models/prunefromws1per0.5ep1000/Epoch-230-Loss-3.5220185688563754.pth
Epoch: 240, Validation Loss: 3.5203, Validation Regression Loss 1.4482, Validation Classification Loss: 2.0721
Saved model models/prunefromws1per0.5ep1000/Epoch-240-Loss-3.5203487191881453.pth
Epoch: 250, Validation Loss: 3.6138, Validation Regression Loss 1.5230, Validation Classification Loss: 2.0908
Saved model models/prunefromws1per0.5ep1000/Epoch-250-Loss-3.61378812789917.pth
Epoch: 260, Validation Loss: 3.5251, Validation Regression Loss 1.4312, Validation Classification Loss: 2.0939
Saved model models/prunefromws1per0.5ep1000/Epoch-260-Loss-3.525110755647932.pth
Epoch: 270, Validation Loss: 3.5804, Validation Regression Loss 1.4781, Validation Classification Loss: 2.1023
Saved model models/prunefromws1per0.5ep1000/Epoch-270-Loss-3.580399819782802.pth
Epoch: 280, Validation Loss: 3.5238, Validation Regression Loss 1.4410, Validation Classification Loss: 2.0828
Saved model models/prunefromws1per0.5ep1000/Epoch-280-Loss-3.5238376344953264.pth
Epoch: 290, Validation Loss: 3.6142, Validation Regression Loss 1.5158, Validation Classification Loss: 2.0984
Saved model models/prunefromws1per0.5ep1000/Epoch-290-Loss-3.6142118658338274.pth
Epoch: 300, Validation Loss: 3.5988, Validation Regression Loss 1.4893, Validation Classification Loss: 2.1094
Saved model models/prunefromws1per0.5ep1000/Epoch-300-Loss-3.5987906455993652.pth
Epoch: 310, Validation Loss: 3.5185, Validation Regression Loss 1.4372, Validation Classification Loss: 2.0813
Saved model models/prunefromws1per0.5ep1000/Epoch-310-Loss-3.5185323783329556.pth
Epoch: 320, Validation Loss: 3.5314, Validation Regression Loss 1.4660, Validation Classification Loss: 2.0654
Saved model models/prunefromws1per0.5ep1000/Epoch-320-Loss-3.531371763774327.pth
Epoch: 330, Validation Loss: 3.5541, Validation Regression Loss 1.4595, Validation Classification Loss: 2.0947
Saved model models/prunefromws1per0.5ep1000/Epoch-330-Loss-3.554126262664795.pth
Epoch: 340, Validation Loss: 3.5406, Validation Regression Loss 1.4716, Validation Classification Loss: 2.0690
Saved model models/prunefromws1per0.5ep1000/Epoch-340-Loss-3.540557316371373.pth
Epoch: 350, Validation Loss: 3.5072, Validation Regression Loss 1.4436, Validation Classification Loss: 2.0635
Saved model models/prunefromws1per0.5ep1000/Epoch-350-Loss-3.5071608339037215.pth
Epoch: 360, Validation Loss: 3.5435, Validation Regression Loss 1.4573, Validation Classification Loss: 2.0863
Saved model models/prunefromws1per0.5ep1000/Epoch-360-Loss-3.543525525501796.pth
Epoch: 370, Validation Loss: 3.5326, Validation Regression Loss 1.4476, Validation Classification Loss: 2.0849
Saved model models/prunefromws1per0.5ep1000/Epoch-370-Loss-3.5325933524540494.pth
Epoch: 380, Validation Loss: 3.5406, Validation Regression Loss 1.4603, Validation Classification Loss: 2.0803
Saved model models/prunefromws1per0.5ep1000/Epoch-380-Loss-3.5405801364353726.pth
Epoch: 390, Validation Loss: 3.5369, Validation Regression Loss 1.4559, Validation Classification Loss: 2.0811
Saved model models/prunefromws1per0.5ep1000/Epoch-390-Loss-3.5369069576263428.pth
Epoch: 400, Validation Loss: 3.5949, Validation Regression Loss 1.4509, Validation Classification Loss: 2.1440
Saved model models/prunefromws1per0.5ep1000/Epoch-400-Loss-3.594917127064296.pth
Epoch: 410, Validation Loss: 3.5331, Validation Regression Loss 1.4498, Validation Classification Loss: 2.0833
Saved model models/prunefromws1per0.5ep1000/Epoch-410-Loss-3.5331344263894215.pth
Epoch: 420, Validation Loss: 3.5673, Validation Regression Loss 1.5012, Validation Classification Loss: 2.0662
Saved model models/prunefromws1per0.5ep1000/Epoch-420-Loss-3.567336525235857.pth
Epoch: 430, Validation Loss: 3.5510, Validation Regression Loss 1.4457, Validation Classification Loss: 2.1053
Saved model models/prunefromws1per0.5ep1000/Epoch-430-Loss-3.5510203497750417.pth
Epoch: 440, Validation Loss: 3.5321, Validation Regression Loss 1.4332, Validation Classification Loss: 2.0989
Saved model models/prunefromws1per0.5ep1000/Epoch-440-Loss-3.5320910045078824.pth
Epoch: 450, Validation Loss: 3.5142, Validation Regression Loss 1.4446, Validation Classification Loss: 2.0696
Saved model models/prunefromws1per0.5ep1000/Epoch-450-Loss-3.5141990865979875.pth
Epoch: 460, Validation Loss: 3.5284, Validation Regression Loss 1.4249, Validation Classification Loss: 2.1036
Saved model models/prunefromws1per0.5ep1000/Epoch-460-Loss-3.5284066200256348.pth
Epoch: 470, Validation Loss: 3.4616, Validation Regression Loss 1.3698, Validation Classification Loss: 2.0918
Saved model models/prunefromws1per0.5ep1000/Epoch-470-Loss-3.4615786416190013.pth
Epoch: 480, Validation Loss: 3.5468, Validation Regression Loss 1.4341, Validation Classification Loss: 2.1127
Saved model models/prunefromws1per0.5ep1000/Epoch-480-Loss-3.5467872619628906.pth
Epoch: 490, Validation Loss: 3.4725, Validation Regression Loss 1.4002, Validation Classification Loss: 2.0723
Saved model models/prunefromws1per0.5ep1000/Epoch-490-Loss-3.4725053991590227.pth
Epoch: 500, Validation Loss: 3.5504, Validation Regression Loss 1.4453, Validation Classification Loss: 2.1052
Saved model models/prunefromws1per0.5ep1000/Epoch-500-Loss-3.550448145185198.pth
Epoch: 510, Validation Loss: 3.5218, Validation Regression Loss 1.4402, Validation Classification Loss: 2.0817
Saved model models/prunefromws1per0.5ep1000/Epoch-510-Loss-3.5218303544180736.pth
Epoch: 520, Validation Loss: 3.5518, Validation Regression Loss 1.4483, Validation Classification Loss: 2.1035
Saved model models/prunefromws1per0.5ep1000/Epoch-520-Loss-3.551753146307809.pth
Epoch: 530, Validation Loss: 3.6287, Validation Regression Loss 1.5191, Validation Classification Loss: 2.1096
Saved model models/prunefromws1per0.5ep1000/Epoch-530-Loss-3.6287300246102467.pth
Epoch: 540, Validation Loss: 3.4707, Validation Regression Loss 1.3746, Validation Classification Loss: 2.0961
Saved model models/prunefromws1per0.5ep1000/Epoch-540-Loss-3.4706923961639404.pth
Epoch: 550, Validation Loss: 3.5162, Validation Regression Loss 1.4161, Validation Classification Loss: 2.1001
Saved model models/prunefromws1per0.5ep1000/Epoch-550-Loss-3.5162191731589183.pth
Epoch: 560, Validation Loss: 3.5189, Validation Regression Loss 1.4163, Validation Classification Loss: 2.1026
Saved model models/prunefromws1per0.5ep1000/Epoch-560-Loss-3.5189089434487477.pth
Epoch: 570, Validation Loss: 3.5173, Validation Regression Loss 1.3976, Validation Classification Loss: 2.1198
Saved model models/prunefromws1per0.5ep1000/Epoch-570-Loss-3.517312322344099.pth
Epoch: 580, Validation Loss: 3.5104, Validation Regression Loss 1.4030, Validation Classification Loss: 2.1074
Saved model models/prunefromws1per0.5ep1000/Epoch-580-Loss-3.5103987625667026.pth
Epoch: 590, Validation Loss: 3.5166, Validation Regression Loss 1.4028, Validation Classification Loss: 2.1138
Saved model models/prunefromws1per0.5ep1000/Epoch-590-Loss-3.5165701593671526.pth
Epoch: 600, Validation Loss: 3.5364, Validation Regression Loss 1.3995, Validation Classification Loss: 2.1369
Saved model models/prunefromws1per0.5ep1000/Epoch-600-Loss-3.5364135674067905.pth
Epoch: 610, Validation Loss: 3.5528, Validation Regression Loss 1.4178, Validation Classification Loss: 2.1350
Saved model models/prunefromws1per0.5ep1000/Epoch-610-Loss-3.55279346874782.pth
Epoch: 620, Validation Loss: 3.5723, Validation Regression Loss 1.4439, Validation Classification Loss: 2.1284
Saved model models/prunefromws1per0.5ep1000/Epoch-620-Loss-3.57227509362357.pth
Epoch: 630, Validation Loss: 3.5628, Validation Regression Loss 1.4382, Validation Classification Loss: 2.1246
Saved model models/prunefromws1per0.5ep1000/Epoch-630-Loss-3.5627825600760326.pth
Epoch: 640, Validation Loss: 3.5578, Validation Regression Loss 1.4314, Validation Classification Loss: 2.1264
Saved model models/prunefromws1per0.5ep1000/Epoch-640-Loss-3.5577968869890486.pth
Epoch: 650, Validation Loss: 3.5511, Validation Regression Loss 1.4265, Validation Classification Loss: 2.1246
Saved model models/prunefromws1per0.5ep1000/Epoch-650-Loss-3.551135778427124.pth
Epoch: 660, Validation Loss: 3.5165, Validation Regression Loss 1.4010, Validation Classification Loss: 2.1154
Saved model models/prunefromws1per0.5ep1000/Epoch-660-Loss-3.5164506435394287.pth
Epoch: 670, Validation Loss: 3.5278, Validation Regression Loss 1.4355, Validation Classification Loss: 2.0923
Saved model models/prunefromws1per0.5ep1000/Epoch-670-Loss-3.527792521885463.pth
Epoch: 680, Validation Loss: 3.5519, Validation Regression Loss 1.4294, Validation Classification Loss: 2.1225
Saved model models/prunefromws1per0.5ep1000/Epoch-680-Loss-3.5518854004996165.pth
Epoch: 690, Validation Loss: 3.5703, Validation Regression Loss 1.4353, Validation Classification Loss: 2.1350
Saved model models/prunefromws1per0.5ep1000/Epoch-690-Loss-3.5702673367091586.pth
Epoch: 700, Validation Loss: 3.5272, Validation Regression Loss 1.4114, Validation Classification Loss: 2.1159
Saved model models/prunefromws1per0.5ep1000/Epoch-700-Loss-3.527249336242676.pth
Epoch: 710, Validation Loss: 3.4816, Validation Regression Loss 1.3874, Validation Classification Loss: 2.0942
Saved model models/prunefromws1per0.5ep1000/Epoch-710-Loss-3.481619800840105.pth
Epoch: 720, Validation Loss: 3.5051, Validation Regression Loss 1.4118, Validation Classification Loss: 2.0933
Saved model models/prunefromws1per0.5ep1000/Epoch-720-Loss-3.5051365920475552.pth
Epoch: 730, Validation Loss: 3.5062, Validation Regression Loss 1.3960, Validation Classification Loss: 2.1102
Saved model models/prunefromws1per0.5ep1000/Epoch-730-Loss-3.506180695125035.pth
Epoch: 740, Validation Loss: 3.5144, Validation Regression Loss 1.4041, Validation Classification Loss: 2.1103
Saved model models/prunefromws1per0.5ep1000/Epoch-740-Loss-3.5143984385899136.pth
Epoch: 750, Validation Loss: 3.5005, Validation Regression Loss 1.3803, Validation Classification Loss: 2.1202
Saved model models/prunefromws1per0.5ep1000/Epoch-750-Loss-3.5004685265677318.pth
Epoch: 760, Validation Loss: 3.4957, Validation Regression Loss 1.4024, Validation Classification Loss: 2.0933
Saved model models/prunefromws1per0.5ep1000/Epoch-760-Loss-3.4957200459071567.pth
Epoch: 770, Validation Loss: 3.5039, Validation Regression Loss 1.3841, Validation Classification Loss: 2.1198
Saved model models/prunefromws1per0.5ep1000/Epoch-770-Loss-3.5038561139787947.pth
Epoch: 780, Validation Loss: 3.5292, Validation Regression Loss 1.4202, Validation Classification Loss: 2.1090
Saved model models/prunefromws1per0.5ep1000/Epoch-780-Loss-3.5291570254734586.pth
Epoch: 790, Validation Loss: 3.5449, Validation Regression Loss 1.4264, Validation Classification Loss: 2.1186
Saved model models/prunefromws1per0.5ep1000/Epoch-790-Loss-3.5449416978018626.pth
Epoch: 800, Validation Loss: 3.5129, Validation Regression Loss 1.4021, Validation Classification Loss: 2.1109
Saved model models/prunefromws1per0.5ep1000/Epoch-800-Loss-3.512914146695818.pth
Epoch: 810, Validation Loss: 3.4878, Validation Regression Loss 1.3846, Validation Classification Loss: 2.1031
Saved model models/prunefromws1per0.5ep1000/Epoch-810-Loss-3.4877683094569614.pth
Epoch: 820, Validation Loss: 3.5266, Validation Regression Loss 1.4056, Validation Classification Loss: 2.1210
Saved model models/prunefromws1per0.5ep1000/Epoch-820-Loss-3.5265824794769287.pth
Epoch: 830, Validation Loss: 3.5301, Validation Regression Loss 1.4109, Validation Classification Loss: 2.1192
Saved model models/prunefromws1per0.5ep1000/Epoch-830-Loss-3.530132361820766.pth
Epoch: 840, Validation Loss: 3.5062, Validation Regression Loss 1.3963, Validation Classification Loss: 2.1099
Saved model models/prunefromws1per0.5ep1000/Epoch-840-Loss-3.5061946596418108.pth
Epoch: 850, Validation Loss: 3.4864, Validation Regression Loss 1.3837, Validation Classification Loss: 2.1027
Saved model models/prunefromws1per0.5ep1000/Epoch-850-Loss-3.4863692011151994.pth
Epoch: 860, Validation Loss: 3.5003, Validation Regression Loss 1.3921, Validation Classification Loss: 2.1082
Saved model models/prunefromws1per0.5ep1000/Epoch-860-Loss-3.5003031321934293.pth
Epoch: 870, Validation Loss: 3.5001, Validation Regression Loss 1.3879, Validation Classification Loss: 2.1121
Saved model models/prunefromws1per0.5ep1000/Epoch-870-Loss-3.5000603880201067.pth
Epoch: 880, Validation Loss: 3.4979, Validation Regression Loss 1.3848, Validation Classification Loss: 2.1131
Saved model models/prunefromws1per0.5ep1000/Epoch-880-Loss-3.4978722504207065.pth
Epoch: 890, Validation Loss: 3.4863, Validation Regression Loss 1.3726, Validation Classification Loss: 2.1137
Saved model models/prunefromws1per0.5ep1000/Epoch-890-Loss-3.4862849371773854.pth
Epoch: 900, Validation Loss: 3.4997, Validation Regression Loss 1.3841, Validation Classification Loss: 2.1156
Saved model models/prunefromws1per0.5ep1000/Epoch-900-Loss-3.4996774877820696.pth
Epoch: 910, Validation Loss: 3.4900, Validation Regression Loss 1.3897, Validation Classification Loss: 2.1002
Saved model models/prunefromws1per0.5ep1000/Epoch-910-Loss-3.4899555955614363.pth
Epoch: 920, Validation Loss: 3.4818, Validation Regression Loss 1.3754, Validation Classification Loss: 2.1064
Saved model models/prunefromws1per0.5ep1000/Epoch-920-Loss-3.4818176882607594.pth
Epoch: 930, Validation Loss: 3.4955, Validation Regression Loss 1.3861, Validation Classification Loss: 2.1094
Saved model models/prunefromws1per0.5ep1000/Epoch-930-Loss-3.4955344881330217.pth
Epoch: 940, Validation Loss: 3.4927, Validation Regression Loss 1.3772, Validation Classification Loss: 2.1155
Saved model models/prunefromws1per0.5ep1000/Epoch-940-Loss-3.4927014963967458.pth
Epoch: 950, Validation Loss: 3.4925, Validation Regression Loss 1.3854, Validation Classification Loss: 2.1070
Saved model models/prunefromws1per0.5ep1000/Epoch-950-Loss-3.4924815041678294.pth
Epoch: 960, Validation Loss: 3.5096, Validation Regression Loss 1.3972, Validation Classification Loss: 2.1124
Saved model models/prunefromws1per0.5ep1000/Epoch-960-Loss-3.5095728806086948.pth
Epoch: 970, Validation Loss: 3.5000, Validation Regression Loss 1.3914, Validation Classification Loss: 2.1086
Saved model models/prunefromws1per0.5ep1000/Epoch-970-Loss-3.49995071547372.pth
Epoch: 980, Validation Loss: 3.4987, Validation Regression Loss 1.3928, Validation Classification Loss: 2.1059
Saved model models/prunefromws1per0.5ep1000/Epoch-980-Loss-3.498739344733102.pth
Epoch: 990, Validation Loss: 3.4942, Validation Regression Loss 1.3901, Validation Classification Loss: 2.1041
Saved model models/prunefromws1per0.5ep1000/Epoch-990-Loss-3.4941935879843578.pth
Epoch: 999, Validation Loss: 3.4975, Validation Regression Loss 1.3895, Validation Classification Loss: 2.1080
Saved model models/prunefromws1per0.5ep1000/Epoch-999-Loss-3.4974870341164723.pth
