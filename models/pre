2022-05-25 03:17:34,398 - root - INFO - Use Cuda.
2022-05-25 03:17:34,398 - root - INFO - Namespace(balance_data=False, base_net=None, base_net_lr=None, batch_size=8, checkpoint_folder='models/pretrain_open', dataset_type='voc', datasets=['CrowdHuman'], debug_steps=100, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, gpu='3', loss='smoothl1', lr=0.01, mb2_width_mult=1.0, milestones='80,100', momentum=0.9, net='mb1-ssd-lite-025extra', num_epochs=300, num_workers=8, optimizer='SGD', pretrained_ssd='models/remake/mb1-ssd-lite-025extra-Epoch-399-Loss-3.6709517410823276.pth', resume=None, scheduler='cosine', t_max=300.0, use_cuda=True, validation_dataset='CrowdHuman', validation_epochs=5, weight_decay=0.0005, width_mult=0.25)
2022-05-25 03:17:34,399 - root - INFO - Prepare training datasets.
2022-05-25 03:17:34,402 - root - INFO - No labels file, using default VOC classes.
2022-05-25 03:17:34,445 - root - INFO - Stored labels into file models/pretrain_open/voc-model-labels.txt.
2022-05-25 03:17:34,445 - root - INFO - Train dataset size: 4140
2022-05-25 03:17:34,446 - root - INFO - Prepare Validation datasets.
2022-05-25 03:17:34,447 - root - INFO - No labels file, using default VOC classes.
2022-05-25 03:17:34,447 - root - INFO - validation dataset size: 360
2022-05-25 03:17:34,447 - root - INFO - Build network.
2022-05-25 03:17:34,477 - root - INFO - Init from pretrained ssd models/remake/mb1-ssd-lite-025extra-Epoch-399-Loss-3.6709517410823276.pth
2022-05-25 03:17:34,515 - root - INFO - Took 0.04 seconds to load the model.
2022-05-25 03:17:38,159 - root - INFO - Learning rate: 0.01, Base net learning rate: 0.01, Extra Layers learning rate: 0.01.
2022-05-25 03:17:38,160 - root - INFO - Uses CosineAnnealingLR scheduler.
2022-05-25 03:17:38,160 - root - INFO - Start training from epoch 0.
/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Traceback (most recent call last):
  File "train_ssd.py", line 393, in <module>
    device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)
  File "train_ssd.py", line 141, in train
    for i, data in enumerate(loader):
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/usr/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/usr/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/usr/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
