root-- VOC2007
Pruning round 1, load model from models/ws0.15bs16/mb1-ssd-lite-025extra-Epoch-1599-Loss-3.460315772465297.pth
SSD(
  (base_net): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(4, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=7, bias=False)
      (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(7, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)
      (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(13, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13, bias=False)
      (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(13, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)
      (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(25, 25, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(25, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=25, bias=False)
      (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(25, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50, bias=False)
      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(50, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50, bias=False)
      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(50, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50, bias=False)
      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(50, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50, bias=False)
      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(50, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=50, bias=False)
      (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(50, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=100, bias=False)
      (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(100, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (extras): ModuleList(
    (0): Sequential(
      (0): Conv2d(80, 25, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(25, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=25)
        (1): ReLU()
        (2): Conv2d(25, 40, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): Sequential(
      (0): Conv2d(40, 13, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13)
        (1): ReLU()
        (2): Conv2d(13, 20, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): Sequential(
      (0): Conv2d(20, 13, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13)
        (1): ReLU()
        (2): Conv2d(13, 20, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): Sequential(
      (0): Conv2d(20, 13, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(13, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13)
        (1): ReLU()
        (2): Conv2d(13, 31, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (classification_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)
      (1): ReLU()
      (2): Conv2d(80, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40)
      (1): ReLU()
      (2): Conv2d(40, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20)
      (1): ReLU()
      (2): Conv2d(20, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20)
      (1): ReLU()
      (2): Conv2d(20, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(31, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (regression_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (1): ReLU()
      (2): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80)
      (1): ReLU()
      (2): Conv2d(80, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40)
      (1): ReLU()
      (2): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20)
      (1): ReLU()
      (2): Conv2d(20, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20)
      (1): ReLU()
      (2): Conv2d(20, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(31, 24, kernel_size=(1, 1), stride=(1, 1))
  )
  (source_layer_add_ons): ModuleList()
)
Saved prune model models/prunews0.15per0.2lr0.01/prune.pth
Number of Parameters: 0.0M
Epoch: 0, Validation Loss: 4.4112, Validation Regression Loss 2.1355, Validation Classification Loss: 2.2757
Saved model models/prunews0.15per0.2lr0.01/Epoch-0-Loss-4.411163534436907.pth
Epoch: 10, Validation Loss: 4.1049, Validation Regression Loss 1.8828, Validation Classification Loss: 2.2221
Saved model models/prunews0.15per0.2lr0.01/Epoch-10-Loss-4.104944671903338.pth
Epoch: 20, Validation Loss: 4.0195, Validation Regression Loss 1.8107, Validation Classification Loss: 2.2088
Saved model models/prunews0.15per0.2lr0.01/Epoch-20-Loss-4.019519431250436.pth
Epoch: 30, Validation Loss: 3.9792, Validation Regression Loss 1.7790, Validation Classification Loss: 2.2002
Saved model models/prunews0.15per0.2lr0.01/Epoch-30-Loss-3.97920366695949.pth
Epoch: 40, Validation Loss: 4.8959, Validation Regression Loss 2.6837, Validation Classification Loss: 2.2122
Saved model models/prunews0.15per0.2lr0.01/Epoch-40-Loss-4.895852974482945.pth
Epoch: 50, Validation Loss: 3.9031, Validation Regression Loss 1.7043, Validation Classification Loss: 2.1989
Saved model models/prunews0.15per0.2lr0.01/Epoch-50-Loss-3.903146743774414.pth
Epoch: 60, Validation Loss: 4.1032, Validation Regression Loss 1.8908, Validation Classification Loss: 2.2124
Saved model models/prunews0.15per0.2lr0.01/Epoch-60-Loss-4.1031738349369595.pth
Epoch: 70, Validation Loss: 3.8819, Validation Regression Loss 1.6999, Validation Classification Loss: 2.1819
Saved model models/prunews0.15per0.2lr0.01/Epoch-70-Loss-3.8818558284214566.pth
Epoch: 80, Validation Loss: 3.9674, Validation Regression Loss 1.7962, Validation Classification Loss: 2.1712
Saved model models/prunews0.15per0.2lr0.01/Epoch-80-Loss-3.9673663207462857.pth
Epoch: 90, Validation Loss: 3.8576, Validation Regression Loss 1.6859, Validation Classification Loss: 2.1717
Saved model models/prunews0.15per0.2lr0.01/Epoch-90-Loss-3.8576435020991733.pth
Epoch: 100, Validation Loss: 3.9825, Validation Regression Loss 1.7934, Validation Classification Loss: 2.1891
Saved model models/prunews0.15per0.2lr0.01/Epoch-100-Loss-3.98252694947379.pth
Epoch: 110, Validation Loss: 4.0092, Validation Regression Loss 1.7968, Validation Classification Loss: 2.2124
Saved model models/prunews0.15per0.2lr0.01/Epoch-110-Loss-4.009157623563494.pth
Epoch: 120, Validation Loss: 3.8611, Validation Regression Loss 1.6893, Validation Classification Loss: 2.1718
Saved model models/prunews0.15per0.2lr0.01/Epoch-120-Loss-3.861115115029471.pth
Epoch: 130, Validation Loss: 3.8365, Validation Regression Loss 1.6692, Validation Classification Loss: 2.1673
Saved model models/prunews0.15per0.2lr0.01/Epoch-130-Loss-3.8365433556692943.pth
Epoch: 140, Validation Loss: 4.1205, Validation Regression Loss 1.8880, Validation Classification Loss: 2.2325
Saved model models/prunews0.15per0.2lr0.01/Epoch-140-Loss-4.120461668287005.pth
Epoch: 150, Validation Loss: 3.8069, Validation Regression Loss 1.6413, Validation Classification Loss: 2.1656
Saved model models/prunews0.15per0.2lr0.01/Epoch-150-Loss-3.806902919496809.pth
Epoch: 160, Validation Loss: 3.9348, Validation Regression Loss 1.7372, Validation Classification Loss: 2.1976
Saved model models/prunews0.15per0.2lr0.01/Epoch-160-Loss-3.9348008973257884.pth
Epoch: 170, Validation Loss: 4.0432, Validation Regression Loss 1.8101, Validation Classification Loss: 2.2331
Saved model models/prunews0.15per0.2lr0.01/Epoch-170-Loss-4.043187141418457.pth
Epoch: 180, Validation Loss: 3.9082, Validation Regression Loss 1.7049, Validation Classification Loss: 2.2033
Saved model models/prunews0.15per0.2lr0.01/Epoch-180-Loss-3.908188138689314.pth
Epoch: 190, Validation Loss: 3.8977, Validation Regression Loss 1.7130, Validation Classification Loss: 2.1847
Saved model models/prunews0.15per0.2lr0.01/Epoch-190-Loss-3.897737434932164.pth
Epoch: 200, Validation Loss: 3.8941, Validation Regression Loss 1.7198, Validation Classification Loss: 2.1743
Saved model models/prunews0.15per0.2lr0.01/Epoch-200-Loss-3.894148758479527.pth
Epoch: 210, Validation Loss: 3.8833, Validation Regression Loss 1.7199, Validation Classification Loss: 2.1633
Saved model models/prunews0.15per0.2lr0.01/Epoch-210-Loss-3.8832708426884244.pth
Epoch: 220, Validation Loss: 3.8139, Validation Regression Loss 1.6593, Validation Classification Loss: 2.1546
Saved model models/prunews0.15per0.2lr0.01/Epoch-220-Loss-3.8139165810176303.pth
Epoch: 230, Validation Loss: 3.7926, Validation Regression Loss 1.6335, Validation Classification Loss: 2.1591
Saved model models/prunews0.15per0.2lr0.01/Epoch-230-Loss-3.7925905159541538.pth
Epoch: 240, Validation Loss: 3.7326, Validation Regression Loss 1.5846, Validation Classification Loss: 2.1481
Saved model models/prunews0.15per0.2lr0.01/Epoch-240-Loss-3.732628379549299.pth
Epoch: 250, Validation Loss: 3.8562, Validation Regression Loss 1.6850, Validation Classification Loss: 2.1712
Saved model models/prunews0.15per0.2lr0.01/Epoch-250-Loss-3.856170722416469.pth
Epoch: 260, Validation Loss: 3.7596, Validation Regression Loss 1.5958, Validation Classification Loss: 2.1638
Saved model models/prunews0.15per0.2lr0.01/Epoch-260-Loss-3.75964287349156.pth
Epoch: 270, Validation Loss: 3.8381, Validation Regression Loss 1.6692, Validation Classification Loss: 2.1689
Saved model models/prunews0.15per0.2lr0.01/Epoch-270-Loss-3.838085787636893.pth
Epoch: 280, Validation Loss: 3.8167, Validation Regression Loss 1.6493, Validation Classification Loss: 2.1674
Saved model models/prunews0.15per0.2lr0.01/Epoch-280-Loss-3.8166868346078053.pth
Epoch: 290, Validation Loss: 3.7661, Validation Regression Loss 1.6194, Validation Classification Loss: 2.1468
Saved model models/prunews0.15per0.2lr0.01/Epoch-290-Loss-3.7661242485046387.pth
Epoch: 300, Validation Loss: 3.8089, Validation Regression Loss 1.6274, Validation Classification Loss: 2.1815
Saved model models/prunews0.15per0.2lr0.01/Epoch-300-Loss-3.8089145251682828.pth
Epoch: 310, Validation Loss: 3.7832, Validation Regression Loss 1.6172, Validation Classification Loss: 2.1660
Saved model models/prunews0.15per0.2lr0.01/Epoch-310-Loss-3.783157995768956.pth
Epoch: 320, Validation Loss: 3.7606, Validation Regression Loss 1.5813, Validation Classification Loss: 2.1793
Saved model models/prunews0.15per0.2lr0.01/Epoch-320-Loss-3.7606046540396556.pth
Epoch: 330, Validation Loss: 3.7565, Validation Regression Loss 1.5929, Validation Classification Loss: 2.1636
Saved model models/prunews0.15per0.2lr0.01/Epoch-330-Loss-3.7564585549490794.pth
Epoch: 340, Validation Loss: 3.9403, Validation Regression Loss 1.7598, Validation Classification Loss: 2.1805
Saved model models/prunews0.15per0.2lr0.01/Epoch-340-Loss-3.940286534173148.pth
Epoch: 350, Validation Loss: 3.8063, Validation Regression Loss 1.6649, Validation Classification Loss: 2.1414
Saved model models/prunews0.15per0.2lr0.01/Epoch-350-Loss-3.806280715124948.pth
Epoch: 360, Validation Loss: 3.7552, Validation Regression Loss 1.6082, Validation Classification Loss: 2.1470
Saved model models/prunews0.15per0.2lr0.01/Epoch-360-Loss-3.755222797393799.pth
Epoch: 370, Validation Loss: 3.9736, Validation Regression Loss 1.7556, Validation Classification Loss: 2.2180
Saved model models/prunews0.15per0.2lr0.01/Epoch-370-Loss-3.973587921687535.pth
Epoch: 380, Validation Loss: 3.7540, Validation Regression Loss 1.5874, Validation Classification Loss: 2.1666
Saved model models/prunews0.15per0.2lr0.01/Epoch-380-Loss-3.7540081569126675.pth
Epoch: 390, Validation Loss: 3.8178, Validation Regression Loss 1.6324, Validation Classification Loss: 2.1854
Saved model models/prunews0.15per0.2lr0.01/Epoch-390-Loss-3.8177798134940013.pth
Epoch: 400, Validation Loss: 3.8076, Validation Regression Loss 1.6577, Validation Classification Loss: 2.1499
Saved model models/prunews0.15per0.2lr0.01/Epoch-400-Loss-3.8076020649501254.pth
Epoch: 410, Validation Loss: 3.8035, Validation Regression Loss 1.6418, Validation Classification Loss: 2.1617
Saved model models/prunews0.15per0.2lr0.01/Epoch-410-Loss-3.803516456059047.pth
Epoch: 420, Validation Loss: 3.7100, Validation Regression Loss 1.5851, Validation Classification Loss: 2.1248
Saved model models/prunews0.15per0.2lr0.01/Epoch-420-Loss-3.7099561350686208.pth
Epoch: 430, Validation Loss: 3.8033, Validation Regression Loss 1.6777, Validation Classification Loss: 2.1257
Saved model models/prunews0.15per0.2lr0.01/Epoch-430-Loss-3.803318364279611.pth
Epoch: 440, Validation Loss: 3.7141, Validation Regression Loss 1.5725, Validation Classification Loss: 2.1416
Saved model models/prunews0.15per0.2lr0.01/Epoch-440-Loss-3.7140917437417165.pth
Epoch: 450, Validation Loss: 3.6981, Validation Regression Loss 1.5429, Validation Classification Loss: 2.1553
Saved model models/prunews0.15per0.2lr0.01/Epoch-450-Loss-3.69811817577907.pth
Epoch: 460, Validation Loss: 3.7392, Validation Regression Loss 1.5854, Validation Classification Loss: 2.1538
Saved model models/prunews0.15per0.2lr0.01/Epoch-460-Loss-3.739152124949864.pth
Epoch: 470, Validation Loss: 3.7029, Validation Regression Loss 1.5476, Validation Classification Loss: 2.1553
Saved model models/prunews0.15per0.2lr0.01/Epoch-470-Loss-3.7029473781585693.pth
Epoch: 480, Validation Loss: 3.7684, Validation Regression Loss 1.6060, Validation Classification Loss: 2.1624
Saved model models/prunews0.15per0.2lr0.01/Epoch-480-Loss-3.7683749880109514.pth
Epoch: 490, Validation Loss: 3.6877, Validation Regression Loss 1.5409, Validation Classification Loss: 2.1468
Saved model models/prunews0.15per0.2lr0.01/Epoch-490-Loss-3.6876582077571323.pth
Epoch: 500, Validation Loss: 3.7427, Validation Regression Loss 1.5692, Validation Classification Loss: 2.1735
Saved model models/prunews0.15per0.2lr0.01/Epoch-500-Loss-3.7427285739353726.pth
Epoch: 510, Validation Loss: 3.7298, Validation Regression Loss 1.5932, Validation Classification Loss: 2.1366
Saved model models/prunews0.15per0.2lr0.01/Epoch-510-Loss-3.7298313549586704.pth
Epoch: 520, Validation Loss: 3.7766, Validation Regression Loss 1.6086, Validation Classification Loss: 2.1680
Saved model models/prunews0.15per0.2lr0.01/Epoch-520-Loss-3.776602336338588.pth
Epoch: 530, Validation Loss: 3.7107, Validation Regression Loss 1.5792, Validation Classification Loss: 2.1315
Saved model models/prunews0.15per0.2lr0.01/Epoch-530-Loss-3.710665396281651.pth
Epoch: 540, Validation Loss: 3.7601, Validation Regression Loss 1.5829, Validation Classification Loss: 2.1772
Saved model models/prunews0.15per0.2lr0.01/Epoch-540-Loss-3.760083164487566.pth
Epoch: 550, Validation Loss: 3.8109, Validation Regression Loss 1.6389, Validation Classification Loss: 2.1719
Saved model models/prunews0.15per0.2lr0.01/Epoch-550-Loss-3.810877799987793.pth
Epoch: 560, Validation Loss: 3.8621, Validation Regression Loss 1.6421, Validation Classification Loss: 2.2200
Saved model models/prunews0.15per0.2lr0.01/Epoch-560-Loss-3.862149238586426.pth
Epoch: 570, Validation Loss: 3.7756, Validation Regression Loss 1.6189, Validation Classification Loss: 2.1567
Saved model models/prunews0.15per0.2lr0.01/Epoch-570-Loss-3.775600399289812.pth
Epoch: 580, Validation Loss: 3.7206, Validation Regression Loss 1.5664, Validation Classification Loss: 2.1542
Saved model models/prunews0.15per0.2lr0.01/Epoch-580-Loss-3.72061596597944.pth
Epoch: 590, Validation Loss: 3.7505, Validation Regression Loss 1.5979, Validation Classification Loss: 2.1526
Saved model models/prunews0.15per0.2lr0.01/Epoch-590-Loss-3.7504658017839705.pth
Epoch: 600, Validation Loss: 3.6677, Validation Regression Loss 1.5327, Validation Classification Loss: 2.1350
Saved model models/prunews0.15per0.2lr0.01/Epoch-600-Loss-3.6677018914903914.pth
Epoch: 610, Validation Loss: 3.6975, Validation Regression Loss 1.5652, Validation Classification Loss: 2.1323
Saved model models/prunews0.15per0.2lr0.01/Epoch-610-Loss-3.697498287473406.pth
Epoch: 620, Validation Loss: 3.6943, Validation Regression Loss 1.5703, Validation Classification Loss: 2.1240
Saved model models/prunews0.15per0.2lr0.01/Epoch-620-Loss-3.6943488461630687.pth
Epoch: 630, Validation Loss: 3.6664, Validation Regression Loss 1.5336, Validation Classification Loss: 2.1328
Saved model models/prunews0.15per0.2lr0.01/Epoch-630-Loss-3.66640727860587.pth
Epoch: 640, Validation Loss: 3.8473, Validation Regression Loss 1.6713, Validation Classification Loss: 2.1760
Saved model models/prunews0.15per0.2lr0.01/Epoch-640-Loss-3.847322906766619.pth
Epoch: 650, Validation Loss: 3.6636, Validation Regression Loss 1.5541, Validation Classification Loss: 2.1095
Saved model models/prunews0.15per0.2lr0.01/Epoch-650-Loss-3.6636010578700473.pth
Epoch: 660, Validation Loss: 3.7545, Validation Regression Loss 1.5927, Validation Classification Loss: 2.1618
Saved model models/prunews0.15per0.2lr0.01/Epoch-660-Loss-3.754472323826381.pth
Epoch: 670, Validation Loss: 3.7025, Validation Regression Loss 1.5631, Validation Classification Loss: 2.1393
Saved model models/prunews0.15per0.2lr0.01/Epoch-670-Loss-3.70245293208531.pth
Epoch: 680, Validation Loss: 3.6914, Validation Regression Loss 1.5411, Validation Classification Loss: 2.1503
Saved model models/prunews0.15per0.2lr0.01/Epoch-680-Loss-3.6914244379316057.pth
Epoch: 690, Validation Loss: 3.7377, Validation Regression Loss 1.5847, Validation Classification Loss: 2.1530
Saved model models/prunews0.15per0.2lr0.01/Epoch-690-Loss-3.7377196039472307.pth
Epoch: 700, Validation Loss: 3.6747, Validation Regression Loss 1.5277, Validation Classification Loss: 2.1470
Saved model models/prunews0.15per0.2lr0.01/Epoch-700-Loss-3.6747051647731235.pth
Epoch: 710, Validation Loss: 3.6924, Validation Regression Loss 1.5471, Validation Classification Loss: 2.1452
Saved model models/prunews0.15per0.2lr0.01/Epoch-710-Loss-3.6923510347093855.pth
Epoch: 720, Validation Loss: 3.6396, Validation Regression Loss 1.5058, Validation Classification Loss: 2.1339
Saved model models/prunews0.15per0.2lr0.01/Epoch-720-Loss-3.6396147864205495.pth
Epoch: 730, Validation Loss: 3.8607, Validation Regression Loss 1.6629, Validation Classification Loss: 2.1977
Saved model models/prunews0.15per0.2lr0.01/Epoch-730-Loss-3.860668454851423.pth
Epoch: 740, Validation Loss: 3.7215, Validation Regression Loss 1.5825, Validation Classification Loss: 2.1389
Saved model models/prunews0.15per0.2lr0.01/Epoch-740-Loss-3.7214597974504744.pth
Epoch: 750, Validation Loss: 3.7118, Validation Regression Loss 1.5696, Validation Classification Loss: 2.1422
Saved model models/prunews0.15per0.2lr0.01/Epoch-750-Loss-3.711780411856515.pth
Epoch: 760, Validation Loss: 3.7452, Validation Regression Loss 1.5942, Validation Classification Loss: 2.1510
Saved model models/prunews0.15per0.2lr0.01/Epoch-760-Loss-3.745199373790196.pth
Epoch: 770, Validation Loss: 3.7469, Validation Regression Loss 1.6287, Validation Classification Loss: 2.1181
Saved model models/prunews0.15per0.2lr0.01/Epoch-770-Loss-3.746861321585519.pth
Epoch: 780, Validation Loss: 3.7390, Validation Regression Loss 1.5728, Validation Classification Loss: 2.1661
Saved model models/prunews0.15per0.2lr0.01/Epoch-780-Loss-3.7389655794416154.pth
Epoch: 790, Validation Loss: 3.6334, Validation Regression Loss 1.4911, Validation Classification Loss: 2.1422
Saved model models/prunews0.15per0.2lr0.01/Epoch-790-Loss-3.6333560603005544.pth
Epoch: 800, Validation Loss: 3.7423, Validation Regression Loss 1.5977, Validation Classification Loss: 2.1447
Saved model models/prunews0.15per0.2lr0.01/Epoch-800-Loss-3.742319175175258.pth
Epoch: 810, Validation Loss: 3.7061, Validation Regression Loss 1.5746, Validation Classification Loss: 2.1315
Saved model models/prunews0.15per0.2lr0.01/Epoch-810-Loss-3.7061116695404053.pth
Epoch: 820, Validation Loss: 3.7360, Validation Regression Loss 1.6033, Validation Classification Loss: 2.1327
Saved model models/prunews0.15per0.2lr0.01/Epoch-820-Loss-3.735997336251395.pth
Epoch: 830, Validation Loss: 3.7226, Validation Regression Loss 1.5740, Validation Classification Loss: 2.1486
Saved model models/prunews0.15per0.2lr0.01/Epoch-830-Loss-3.722630602972848.pth
Epoch: 840, Validation Loss: 3.7057, Validation Regression Loss 1.5569, Validation Classification Loss: 2.1487
Saved model models/prunews0.15per0.2lr0.01/Epoch-840-Loss-3.7056534630911693.pth
Epoch: 850, Validation Loss: 3.7130, Validation Regression Loss 1.5620, Validation Classification Loss: 2.1511
Saved model models/prunews0.15per0.2lr0.01/Epoch-850-Loss-3.7130191326141357.pth
Epoch: 860, Validation Loss: 3.7953, Validation Regression Loss 1.6313, Validation Classification Loss: 2.1640
Saved model models/prunews0.15per0.2lr0.01/Epoch-860-Loss-3.7953332492283414.pth
Epoch: 870, Validation Loss: 3.7688, Validation Regression Loss 1.6070, Validation Classification Loss: 2.1618
Saved model models/prunews0.15per0.2lr0.01/Epoch-870-Loss-3.768787349973406.pth
Epoch: 880, Validation Loss: 3.6758, Validation Regression Loss 1.5241, Validation Classification Loss: 2.1518
Saved model models/prunews0.15per0.2lr0.01/Epoch-880-Loss-3.6758038657052174.pth
Epoch: 890, Validation Loss: 3.6274, Validation Regression Loss 1.4907, Validation Classification Loss: 2.1367
Saved model models/prunews0.15per0.2lr0.01/Epoch-890-Loss-3.627440486635481.pth
Epoch: 900, Validation Loss: 3.6919, Validation Regression Loss 1.5377, Validation Classification Loss: 2.1542
Saved model models/prunews0.15per0.2lr0.01/Epoch-900-Loss-3.6918937478746687.pth
Epoch: 910, Validation Loss: 3.6399, Validation Regression Loss 1.5116, Validation Classification Loss: 2.1283
Saved model models/prunews0.15per0.2lr0.01/Epoch-910-Loss-3.6399422713688443.pth
Epoch: 920, Validation Loss: 3.6832, Validation Regression Loss 1.5331, Validation Classification Loss: 2.1502
Saved model models/prunews0.15per0.2lr0.01/Epoch-920-Loss-3.6832354068756104.pth
Epoch: 930, Validation Loss: 3.6400, Validation Regression Loss 1.5118, Validation Classification Loss: 2.1282
Saved model models/prunews0.15per0.2lr0.01/Epoch-930-Loss-3.6400101525442943.pth
Epoch: 940, Validation Loss: 3.6400, Validation Regression Loss 1.5026, Validation Classification Loss: 2.1374
Saved model models/prunews0.15per0.2lr0.01/Epoch-940-Loss-3.6400183268955777.pth
Epoch: 950, Validation Loss: 3.6148, Validation Regression Loss 1.4790, Validation Classification Loss: 2.1358
Saved model models/prunews0.15per0.2lr0.01/Epoch-950-Loss-3.614791222981044.pth
Epoch: 960, Validation Loss: 3.6238, Validation Regression Loss 1.4782, Validation Classification Loss: 2.1455
Saved model models/prunews0.15per0.2lr0.01/Epoch-960-Loss-3.6237700326102122.pth
Epoch: 970, Validation Loss: 3.6623, Validation Regression Loss 1.5358, Validation Classification Loss: 2.1265
Saved model models/prunews0.15per0.2lr0.01/Epoch-970-Loss-3.6622629846845354.pth
Epoch: 980, Validation Loss: 3.6935, Validation Regression Loss 1.5380, Validation Classification Loss: 2.1555
Saved model models/prunews0.15per0.2lr0.01/Epoch-980-Loss-3.6935174805777415.pth
Epoch: 990, Validation Loss: 3.6096, Validation Regression Loss 1.4999, Validation Classification Loss: 2.1097
Saved model models/prunews0.15per0.2lr0.01/Epoch-990-Loss-3.6095808914729526.pth
Epoch: 1000, Validation Loss: 3.6240, Validation Regression Loss 1.4861, Validation Classification Loss: 2.1379
Saved model models/prunews0.15per0.2lr0.01/Epoch-1000-Loss-3.624007054737636.pth
Epoch: 1010, Validation Loss: 3.6745, Validation Regression Loss 1.5184, Validation Classification Loss: 2.1560
Saved model models/prunews0.15per0.2lr0.01/Epoch-1010-Loss-3.674464225769043.pth
Epoch: 1020, Validation Loss: 3.5489, Validation Regression Loss 1.4492, Validation Classification Loss: 2.0998
Saved model models/prunews0.15per0.2lr0.01/Epoch-1020-Loss-3.548929282597133.pth
Epoch: 1030, Validation Loss: 3.5980, Validation Regression Loss 1.4908, Validation Classification Loss: 2.1071
Saved model models/prunews0.15per0.2lr0.01/Epoch-1030-Loss-3.597951820918492.pth
Epoch: 1040, Validation Loss: 3.5706, Validation Regression Loss 1.4691, Validation Classification Loss: 2.1016
Saved model models/prunews0.15per0.2lr0.01/Epoch-1040-Loss-3.570603132247925.pth
Epoch: 1050, Validation Loss: 3.6110, Validation Regression Loss 1.4975, Validation Classification Loss: 2.1134
Saved model models/prunews0.15per0.2lr0.01/Epoch-1050-Loss-3.6109724725995744.pth
Epoch: 1060, Validation Loss: 3.6171, Validation Regression Loss 1.4962, Validation Classification Loss: 2.1209
Saved model models/prunews0.15per0.2lr0.01/Epoch-1060-Loss-3.6170919963291714.pth
Epoch: 1070, Validation Loss: 3.6042, Validation Regression Loss 1.4942, Validation Classification Loss: 2.1100
Saved model models/prunews0.15per0.2lr0.01/Epoch-1070-Loss-3.604168312890189.pth
Epoch: 1080, Validation Loss: 3.6524, Validation Regression Loss 1.5056, Validation Classification Loss: 2.1468
Saved model models/prunews0.15per0.2lr0.01/Epoch-1080-Loss-3.6523996080671037.pth
Epoch: 1090, Validation Loss: 3.6469, Validation Regression Loss 1.5136, Validation Classification Loss: 2.1333
Saved model models/prunews0.15per0.2lr0.01/Epoch-1090-Loss-3.6468662193843295.pth
Epoch: 1100, Validation Loss: 3.6593, Validation Regression Loss 1.5148, Validation Classification Loss: 2.1445
Saved model models/prunews0.15per0.2lr0.01/Epoch-1100-Loss-3.659280845097133.pth
Epoch: 1110, Validation Loss: 3.6084, Validation Regression Loss 1.4934, Validation Classification Loss: 2.1150
Saved model models/prunews0.15per0.2lr0.01/Epoch-1110-Loss-3.608393907546997.pth
Epoch: 1120, Validation Loss: 3.6493, Validation Regression Loss 1.4912, Validation Classification Loss: 2.1581
Saved model models/prunews0.15per0.2lr0.01/Epoch-1120-Loss-3.649277550833566.pth
Epoch: 1130, Validation Loss: 3.6041, Validation Regression Loss 1.4783, Validation Classification Loss: 2.1258
Saved model models/prunews0.15per0.2lr0.01/Epoch-1130-Loss-3.604100670133318.pth
Epoch: 1140, Validation Loss: 3.6170, Validation Regression Loss 1.5024, Validation Classification Loss: 2.1146
Saved model models/prunews0.15per0.2lr0.01/Epoch-1140-Loss-3.616974183491298.pth
Epoch: 1150, Validation Loss: 3.6146, Validation Regression Loss 1.5068, Validation Classification Loss: 2.1078
Saved model models/prunews0.15per0.2lr0.01/Epoch-1150-Loss-3.614640951156616.pth
Epoch: 1160, Validation Loss: 3.5911, Validation Regression Loss 1.4821, Validation Classification Loss: 2.1089
Saved model models/prunews0.15per0.2lr0.01/Epoch-1160-Loss-3.591057709285191.pth
Epoch: 1170, Validation Loss: 3.5795, Validation Regression Loss 1.4744, Validation Classification Loss: 2.1051
Saved model models/prunews0.15per0.2lr0.01/Epoch-1170-Loss-3.579468318394252.pth
Epoch: 1180, Validation Loss: 3.5902, Validation Regression Loss 1.4661, Validation Classification Loss: 2.1240
Saved model models/prunews0.15per0.2lr0.01/Epoch-1180-Loss-3.590158769062587.pth
Epoch: 1190, Validation Loss: 3.6277, Validation Regression Loss 1.4955, Validation Classification Loss: 2.1322
Saved model models/prunews0.15per0.2lr0.01/Epoch-1190-Loss-3.6277115685599193.pth
Epoch: 1200, Validation Loss: 3.5400, Validation Regression Loss 1.4439, Validation Classification Loss: 2.0961
Saved model models/prunews0.15per0.2lr0.01/Epoch-1200-Loss-3.5400166852133617.pth
Epoch: 1210, Validation Loss: 3.6142, Validation Regression Loss 1.4926, Validation Classification Loss: 2.1217
Saved model models/prunews0.15per0.2lr0.01/Epoch-1210-Loss-3.6142268862043108.pth
Epoch: 1220, Validation Loss: 3.6364, Validation Regression Loss 1.5101, Validation Classification Loss: 2.1263
Saved model models/prunews0.15per0.2lr0.01/Epoch-1220-Loss-3.636416026524135.pth
Epoch: 1230, Validation Loss: 3.5844, Validation Regression Loss 1.4741, Validation Classification Loss: 2.1103
Saved model models/prunews0.15per0.2lr0.01/Epoch-1230-Loss-3.5844292640686035.pth
Epoch: 1240, Validation Loss: 3.5627, Validation Regression Loss 1.4426, Validation Classification Loss: 2.1201
Saved model models/prunews0.15per0.2lr0.01/Epoch-1240-Loss-3.562687260763986.pth
Epoch: 1250, Validation Loss: 3.5619, Validation Regression Loss 1.4569, Validation Classification Loss: 2.1049
Saved model models/prunews0.15per0.2lr0.01/Epoch-1250-Loss-3.5618598801749095.pth
Epoch: 1260, Validation Loss: 3.5225, Validation Regression Loss 1.4327, Validation Classification Loss: 2.0898
Saved model models/prunews0.15per0.2lr0.01/Epoch-1260-Loss-3.522507361003331.pth
Epoch: 1270, Validation Loss: 3.5413, Validation Regression Loss 1.4416, Validation Classification Loss: 2.0997
Saved model models/prunews0.15per0.2lr0.01/Epoch-1270-Loss-3.541309288569859.pth
Epoch: 1280, Validation Loss: 3.5655, Validation Regression Loss 1.4590, Validation Classification Loss: 2.1065
Saved model models/prunews0.15per0.2lr0.01/Epoch-1280-Loss-3.5654880659920827.pth
Epoch: 1290, Validation Loss: 3.5538, Validation Regression Loss 1.4380, Validation Classification Loss: 2.1158
Saved model models/prunews0.15per0.2lr0.01/Epoch-1290-Loss-3.553804738180978.pth
Epoch: 1300, Validation Loss: 3.5631, Validation Regression Loss 1.4552, Validation Classification Loss: 2.1079
Saved model models/prunews0.15per0.2lr0.01/Epoch-1300-Loss-3.563051394053868.pth
Epoch: 1310, Validation Loss: 3.5734, Validation Regression Loss 1.4785, Validation Classification Loss: 2.0949
Saved model models/prunews0.15per0.2lr0.01/Epoch-1310-Loss-3.5733964102608815.pth
Epoch: 1320, Validation Loss: 3.5436, Validation Regression Loss 1.4434, Validation Classification Loss: 2.1002
Saved model models/prunews0.15per0.2lr0.01/Epoch-1320-Loss-3.5436112540108815.pth
Epoch: 1330, Validation Loss: 3.5382, Validation Regression Loss 1.4453, Validation Classification Loss: 2.0930
Saved model models/prunews0.15per0.2lr0.01/Epoch-1330-Loss-3.5382381166730608.pth
Epoch: 1340, Validation Loss: 3.5603, Validation Regression Loss 1.4558, Validation Classification Loss: 2.1045
Saved model models/prunews0.15per0.2lr0.01/Epoch-1340-Loss-3.5602753162384033.pth
Epoch: 1350, Validation Loss: 3.5359, Validation Regression Loss 1.4401, Validation Classification Loss: 2.0958
Saved model models/prunews0.15per0.2lr0.01/Epoch-1350-Loss-3.535853215626308.pth
Epoch: 1360, Validation Loss: 3.5238, Validation Regression Loss 1.4280, Validation Classification Loss: 2.0957
Saved model models/prunews0.15per0.2lr0.01/Epoch-1360-Loss-3.523764065333775.pth
Epoch: 1370, Validation Loss: 3.5537, Validation Regression Loss 1.4379, Validation Classification Loss: 2.1158
Saved model models/prunews0.15per0.2lr0.01/Epoch-1370-Loss-3.553739377430507.pth
Epoch: 1380, Validation Loss: 3.5556, Validation Regression Loss 1.4401, Validation Classification Loss: 2.1155
Saved model models/prunews0.15per0.2lr0.01/Epoch-1380-Loss-3.555592026029314.pth
Epoch: 1390, Validation Loss: 3.5343, Validation Regression Loss 1.4458, Validation Classification Loss: 2.0886
Saved model models/prunews0.15per0.2lr0.01/Epoch-1390-Loss-3.5343497821262906.pth
Epoch: 1400, Validation Loss: 3.5320, Validation Regression Loss 1.4413, Validation Classification Loss: 2.0907
Saved model models/prunews0.15per0.2lr0.01/Epoch-1400-Loss-3.532031944819859.pth
Epoch: 1410, Validation Loss: 3.5565, Validation Regression Loss 1.4503, Validation Classification Loss: 2.1062
Saved model models/prunews0.15per0.2lr0.01/Epoch-1410-Loss-3.5565155233655656.pth
Epoch: 1420, Validation Loss: 3.5482, Validation Regression Loss 1.4491, Validation Classification Loss: 2.0991
Saved model models/prunews0.15per0.2lr0.01/Epoch-1420-Loss-3.5481727804456438.pth
Epoch: 1430, Validation Loss: 3.5522, Validation Regression Loss 1.4491, Validation Classification Loss: 2.1031
Saved model models/prunews0.15per0.2lr0.01/Epoch-1430-Loss-3.5521648951939175.pth
Epoch: 1440, Validation Loss: 3.5583, Validation Regression Loss 1.4541, Validation Classification Loss: 2.1041
Saved model models/prunews0.15per0.2lr0.01/Epoch-1440-Loss-3.5582506316048756.pth
Epoch: 1450, Validation Loss: 3.5396, Validation Regression Loss 1.4440, Validation Classification Loss: 2.0957
Saved model models/prunews0.15per0.2lr0.01/Epoch-1450-Loss-3.539618287767683.pth
Epoch: 1460, Validation Loss: 3.5381, Validation Regression Loss 1.4388, Validation Classification Loss: 2.0993
Saved model models/prunews0.15per0.2lr0.01/Epoch-1460-Loss-3.5380934987749373.pth
Epoch: 1470, Validation Loss: 3.5257, Validation Regression Loss 1.4348, Validation Classification Loss: 2.0909
Saved model models/prunews0.15per0.2lr0.01/Epoch-1470-Loss-3.5257245131901334.pth
Epoch: 1480, Validation Loss: 3.5296, Validation Regression Loss 1.4415, Validation Classification Loss: 2.0881
Saved model models/prunews0.15per0.2lr0.01/Epoch-1480-Loss-3.529611144747053.pth
Epoch: 1490, Validation Loss: 3.5326, Validation Regression Loss 1.4404, Validation Classification Loss: 2.0922
Saved model models/prunews0.15per0.2lr0.01/Epoch-1490-Loss-3.5325839519500732.pth
Epoch: 1500, Validation Loss: 3.5350, Validation Regression Loss 1.4418, Validation Classification Loss: 2.0932
Saved model models/prunews0.15per0.2lr0.01/Epoch-1500-Loss-3.5349665709904263.pth
Epoch: 1510, Validation Loss: 3.5255, Validation Regression Loss 1.4396, Validation Classification Loss: 2.0859
Saved model models/prunews0.15per0.2lr0.01/Epoch-1510-Loss-3.525501183101109.pth
Epoch: 1520, Validation Loss: 3.5341, Validation Regression Loss 1.4411, Validation Classification Loss: 2.0930
Saved model models/prunews0.15per0.2lr0.01/Epoch-1520-Loss-3.534081220626831.pth
Epoch: 1530, Validation Loss: 3.5409, Validation Regression Loss 1.4427, Validation Classification Loss: 2.0982
Saved model models/prunews0.15per0.2lr0.01/Epoch-1530-Loss-3.5409484590802873.pth
Epoch: 1540, Validation Loss: 3.5351, Validation Regression Loss 1.4412, Validation Classification Loss: 2.0939
Saved model models/prunews0.15per0.2lr0.01/Epoch-1540-Loss-3.535065071923392.pth
Epoch: 1550, Validation Loss: 3.5310, Validation Regression Loss 1.4365, Validation Classification Loss: 2.0945
Saved model models/prunews0.15per0.2lr0.01/Epoch-1550-Loss-3.530970335006714.pth
Epoch: 1560, Validation Loss: 3.5309, Validation Regression Loss 1.4353, Validation Classification Loss: 2.0955
Saved model models/prunews0.15per0.2lr0.01/Epoch-1560-Loss-3.53085572378976.pth
Epoch: 1570, Validation Loss: 3.5319, Validation Regression Loss 1.4405, Validation Classification Loss: 2.0913
Saved model models/prunews0.15per0.2lr0.01/Epoch-1570-Loss-3.531874213899885.pth
Epoch: 1580, Validation Loss: 3.5218, Validation Regression Loss 1.4344, Validation Classification Loss: 2.0874
Saved model models/prunews0.15per0.2lr0.01/Epoch-1580-Loss-3.5218190465654646.pth
Epoch: 1590, Validation Loss: 3.5241, Validation Regression Loss 1.4320, Validation Classification Loss: 2.0922
Saved model models/prunews0.15per0.2lr0.01/Epoch-1590-Loss-3.5241499287741527.pth
Epoch: 1599, Validation Loss: 3.5309, Validation Regression Loss 1.4356, Validation Classification Loss: 2.0954
Saved model models/prunews0.15per0.2lr0.01/Epoch-1599-Loss-3.530949762889317.pth
