root-- VOC2007
Pruning round 1, load model from models/pruneFromws1/Epoch-1260-Loss-3.488939012799944.pth
SSD(
  (base_net): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)
      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(8, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(14, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=14, bias=False)
      (1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(14, 14, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(14, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=14, bias=False)
      (1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(14, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=28, bias=False)
      (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(28, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(28, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=28, bias=False)
      (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(28, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=53, bias=False)
      (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(53, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=53, bias=False)
      (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(53, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=53, bias=False)
      (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(53, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=53, bias=False)
      (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(53, 53, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(53, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=53, bias=False)
      (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(53, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=7, bias=False)
      (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(7, 106, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(106, 106, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=106, bias=False)
      (1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(106, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (extras): ModuleList(
    (0): Sequential(
      (0): Conv2d(35, 28, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(28, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=28)
        (1): ReLU()
        (2): Conv2d(28, 18, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): Sequential(
      (0): Conv2d(18, 14, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(14, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=14)
        (1): ReLU()
        (2): Conv2d(14, 10, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): Sequential(
      (0): Conv2d(10, 14, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(14, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=14)
        (1): ReLU()
        (2): Conv2d(14, 10, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): Sequential(
      (0): Conv2d(10, 14, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(14, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=14)
        (1): ReLU()
        (2): Conv2d(14, 83, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (classification_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(35, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=35)
      (1): ReLU()
      (2): Conv2d(35, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=18)
      (1): ReLU()
      (2): Conv2d(18, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10)
      (1): ReLU()
      (2): Conv2d(10, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10)
      (1): ReLU()
      (2): Conv2d(10, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(83, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (regression_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=7)
      (1): ReLU()
      (2): Conv2d(7, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(35, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=35)
      (1): ReLU()
      (2): Conv2d(35, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=18)
      (1): ReLU()
      (2): Conv2d(18, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10)
      (1): ReLU()
      (2): Conv2d(10, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10)
      (1): ReLU()
      (2): Conv2d(10, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(83, 24, kernel_size=(1, 1), stride=(1, 1))
  )
  (source_layer_add_ons): ModuleList()
)
Saved prune model models/prunefrom398per0.2/prune.pth
Number of Parameters: 0.0M
Epoch: 0, Validation Loss: 4.8784, Validation Regression Loss 2.5468, Validation Classification Loss: 2.3315
Saved model models/prunefrom398per0.2/Epoch-0-Loss-4.878388609204974.pth
Epoch: 10, Validation Loss: 4.2400, Validation Regression Loss 2.0059, Validation Classification Loss: 2.2341
Saved model models/prunefrom398per0.2/Epoch-10-Loss-4.239966085978916.pth
Epoch: 20, Validation Loss: 4.0454, Validation Regression Loss 1.8235, Validation Classification Loss: 2.2218
Saved model models/prunefrom398per0.2/Epoch-20-Loss-4.045374734061105.pth
Epoch: 30, Validation Loss: 4.0472, Validation Regression Loss 1.8326, Validation Classification Loss: 2.2146
Saved model models/prunefrom398per0.2/Epoch-30-Loss-4.047169719423566.pth
Epoch: 40, Validation Loss: 3.9776, Validation Regression Loss 1.7654, Validation Classification Loss: 2.2122
Saved model models/prunefrom398per0.2/Epoch-40-Loss-3.9775584765842984.pth
Epoch: 50, Validation Loss: 3.9485, Validation Regression Loss 1.7472, Validation Classification Loss: 2.2013
Saved model models/prunefrom398per0.2/Epoch-50-Loss-3.948523623602731.pth
Epoch: 60, Validation Loss: 3.9268, Validation Regression Loss 1.7230, Validation Classification Loss: 2.2038
Saved model models/prunefrom398per0.2/Epoch-60-Loss-3.9268129893711636.pth
Epoch: 70, Validation Loss: 3.9136, Validation Regression Loss 1.7139, Validation Classification Loss: 2.1997
Saved model models/prunefrom398per0.2/Epoch-70-Loss-3.913626091820853.pth
Epoch: 79, Validation Loss: 3.9122, Validation Regression Loss 1.7118, Validation Classification Loss: 2.2004
Saved model models/prunefrom398per0.2/Epoch-79-Loss-3.9122113500322615.pth
