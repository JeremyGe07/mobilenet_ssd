root-- VOC2007
Pruning round 1, load model from models/ep1000ws1pr/mb1-ssd-lite-Epoch-945-Loss-3.2492578540529524.pth
SSD(
  (base_net): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)
      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (2): Sequential(
      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(24, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (3): Sequential(
      (0): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)
      (1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(47, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(47, 47, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=47, bias=False)
      (1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(47, 93, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(93, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=93, bias=False)
      (1): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(93, 93, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(93, 93, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=93, bias=False)
      (1): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(93, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(185, 185, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=185, bias=False)
      (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(185, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(185, 185, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=185, bias=False)
      (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(185, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(185, 185, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=185, bias=False)
      (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(185, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(185, 185, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=185, bias=False)
      (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(185, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(185, 185, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=185, bias=False)
      (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(185, 67, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(67, 67, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=67, bias=False)
      (1): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(67, 369, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(369, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(369, 369, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=369, bias=False)
      (1): BatchNorm2d(369, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(369, 222, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (4): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (extras): ModuleList(
    (0): Sequential(
      (0): Conv2d(222, 93, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(93, 93, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=93)
        (1): ReLU()
        (2): Conv2d(93, 111, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (1): Sequential(
      (0): Conv2d(111, 47, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(47, 47, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=47)
        (1): ReLU()
        (2): Conv2d(47, 56, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (2): Sequential(
      (0): Conv2d(56, 47, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(47, 47, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=47)
        (1): ReLU()
        (2): Conv2d(47, 56, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (3): Sequential(
      (0): Conv2d(56, 47, kernel_size=(1, 1), stride=(1, 1))
      (1): ReLU()
      (2): Sequential(
        (0): Conv2d(47, 47, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=47)
        (1): ReLU()
        (2): Conv2d(47, 154, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (classification_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(67, 67, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=67)
      (1): ReLU()
      (2): Conv2d(67, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(222, 222, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=222)
      (1): ReLU()
      (2): Conv2d(222, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(111, 111, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=111)
      (1): ReLU()
      (2): Conv2d(111, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56)
      (1): ReLU()
      (2): Conv2d(56, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56)
      (1): ReLU()
      (2): Conv2d(56, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(154, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (regression_headers): ModuleList(
    (0): Sequential(
      (0): Conv2d(67, 67, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=67)
      (1): ReLU()
      (2): Conv2d(67, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): Sequential(
      (0): Conv2d(222, 222, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=222)
      (1): ReLU()
      (2): Conv2d(222, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): Sequential(
      (0): Conv2d(111, 111, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=111)
      (1): ReLU()
      (2): Conv2d(111, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): Sequential(
      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56)
      (1): ReLU()
      (2): Conv2d(56, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (4): Sequential(
      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56)
      (1): ReLU()
      (2): Conv2d(56, 24, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): Conv2d(154, 24, kernel_size=(1, 1), stride=(1, 1))
  )
  (source_layer_add_ons): ModuleList()
)
Saved prune model models/prunefromws1per0.4ep140/prune.pth
Number of Parameters: 0.4M
Epoch: 0, Validation Loss: 4.9216, Validation Regression Loss 2.6202, Validation Classification Loss: 2.3014
Saved model models/prunefromws1per0.4ep140/Epoch-0-Loss-4.9215691430228095.pth
Epoch: 10, Validation Loss: 3.9910, Validation Regression Loss 1.8743, Validation Classification Loss: 2.1167
Saved model models/prunefromws1per0.4ep140/Epoch-10-Loss-3.991020543234689.pth
Epoch: 20, Validation Loss: 3.7118, Validation Regression Loss 1.6191, Validation Classification Loss: 2.0927
Saved model models/prunefromws1per0.4ep140/Epoch-20-Loss-3.711754219872611.pth
Epoch: 30, Validation Loss: 3.6081, Validation Regression Loss 1.5298, Validation Classification Loss: 2.0783
Saved model models/prunefromws1per0.4ep140/Epoch-30-Loss-3.608065434864589.pth
Epoch: 40, Validation Loss: 3.6050, Validation Regression Loss 1.4959, Validation Classification Loss: 2.1091
Saved model models/prunefromws1per0.4ep140/Epoch-40-Loss-3.6049980436052596.pth
Epoch: 50, Validation Loss: 3.5403, Validation Regression Loss 1.4564, Validation Classification Loss: 2.0839
Saved model models/prunefromws1per0.4ep140/Epoch-50-Loss-3.540332010814122.pth
Epoch: 60, Validation Loss: 3.4720, Validation Regression Loss 1.4259, Validation Classification Loss: 2.0461
Saved model models/prunefromws1per0.4ep140/Epoch-60-Loss-3.471987860543387.pth
Epoch: 70, Validation Loss: 3.5095, Validation Regression Loss 1.4378, Validation Classification Loss: 2.0717
Saved model models/prunefromws1per0.4ep140/Epoch-70-Loss-3.5094691685267856.pth
Epoch: 80, Validation Loss: 3.4779, Validation Regression Loss 1.4079, Validation Classification Loss: 2.0699
Saved model models/prunefromws1per0.4ep140/Epoch-80-Loss-3.4778601782662526.pth
Epoch: 90, Validation Loss: 3.4898, Validation Regression Loss 1.3974, Validation Classification Loss: 2.0924
Saved model models/prunefromws1per0.4ep140/Epoch-90-Loss-3.4897965363093784.pth
Epoch: 100, Validation Loss: 3.4490, Validation Regression Loss 1.3798, Validation Classification Loss: 2.0692
Saved model models/prunefromws1per0.4ep140/Epoch-100-Loss-3.4489521980285645.pth
Epoch: 110, Validation Loss: 3.4582, Validation Regression Loss 1.3857, Validation Classification Loss: 2.0726
Saved model models/prunefromws1per0.4ep140/Epoch-110-Loss-3.4582466057368686.pth
Epoch: 120, Validation Loss: 3.4739, Validation Regression Loss 1.3925, Validation Classification Loss: 2.0815
Saved model models/prunefromws1per0.4ep140/Epoch-120-Loss-3.473941837038313.pth
Epoch: 130, Validation Loss: 3.4680, Validation Regression Loss 1.3892, Validation Classification Loss: 2.0787
Saved model models/prunefromws1per0.4ep140/Epoch-130-Loss-3.4679600511278426.pth
Epoch: 139, Validation Loss: 3.4689, Validation Regression Loss 1.3866, Validation Classification Loss: 2.0823
Saved model models/prunefromws1per0.4ep140/Epoch-139-Loss-3.46890013558524.pth
